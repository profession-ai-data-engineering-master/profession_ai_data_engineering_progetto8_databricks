{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "682e7512-5294-47a6-8c27-7b6432ad1e4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Analisi di Wikipedia\n",
    "\n",
    "## Descrizione del Progetto\n",
    "\n",
    "**Wikidata Insights**, un'azienda leader nella gestione di contenuti digitali, è stata incaricata da **Wikipedia** per ottimizzare l'analisi e la categorizzazione dei contenuti di Wikipedia.\n",
    "Per supportare la loro continua espansione e migliorare l'organizzazione delle informazioni, Wikidata Insights ha deciso di condurre un progetto avanzato di **data analysis e machine learning**.\n",
    "L'obiettivo principale è comprendere meglio il vasto patrimonio di contenuti informativi offerti da Wikipedia e sviluppare un sistema di **classificazione automatica** che consenta di categorizzare efficacemente i nuovi articoli futuri.\n",
    "\n",
    "## Obiettivi\n",
    "\n",
    "### 1. Analisi Descrittiva dei Contenuti\n",
    "\n",
    "Il primo obiettivo del progetto è condurre un'**analisi esplorativa dei dati (EDA)** per capire le caratteristiche dei contenuti di Wikipedia suddivisi in diverse categorie tematiche, come ad esempio:\n",
    "\n",
    "* Cultura\n",
    "* Economia\n",
    "* Medicina\n",
    "* Tecnologia\n",
    "* Politica\n",
    "* Scienza\n",
    "  e altre.\n",
    "\n",
    "L'analisi esplorativa prevede:\n",
    "\n",
    "* il **conteggio degli articoli** presenti per ogni categoria.\n",
    "* il **numero medio di parole** per articolo.\n",
    "* la lunghezza dell'articolo **più lungo** e di quello **più corto** per ciascuna categoria.\n",
    "* la creazione di **nuvole di parole** rappresentative per ogni categoria, per identificare i termini più frequenti e rilevanti.\n",
    "\n",
    "### 2. Sviluppo di un Classificatore Automatico\n",
    "\n",
    "Il secondo obiettivo è creare un modello di **machine learning** capace di classificare automaticamente gli articoli in base alla loro categoria.\n",
    "\n",
    "Il sistema di classificazione verrà addestrato utilizzando dati di testo presenti nelle seguenti colonne del dataset:\n",
    "\n",
    "* **Sommario** (`summary`): Introduzione breve dell'articolo.\n",
    "* **Testo Completo** (`documents`): Contenuto completo dell'articolo.\n",
    "\n",
    "### 3. Identificazione di Nuovi Insights\n",
    "\n",
    "L'analisi consentirà anche di ottenere preziosi insights sui contenuti di Wikipedia, come la densità di articoli per categoria o le tendenze linguistiche associate a determinati argomenti.\n",
    "Queste informazioni possono aiutare Wikimedia a migliorare l'organizzazione delle pagine e a ottimizzare i propri sforzi editoriali.\n",
    "\n",
    "## Workflow del Progetto\n",
    "\n",
    "### Caricamento dei Dati\n",
    "\n",
    "I dati è salvato su S3 e reperibile al seguente link:\n",
    "`https://proai-datasets.s3.eu-west-3.amazonaws.com/wikipedia.csv`\n",
    "\n",
    "Utilizzando un framework distribuito come **Databricks**, i dati vengono processati in modo efficiente, partendo da un **Pandas DataFrame** per essere successivamente convertiti in un **Spark DataFrame** e salvati come una tabella chiamata `Wikipedia`.\n",
    "\n",
    "Per caricare il dataset e trasformarlo in una table basta eseguire su Notebook Databricks le seguenti righe di codice:\n",
    "\n",
    "```python\n",
    "!wget https://proai-datasets.s3.eu-west-3.amazonaws.com/wikipedia.csv\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"/databricks/driver/wikipedia.csv\")\n",
    "spark_df = spark.createDataFrame(dataset)\n",
    "spark_df = spark_df.drop(\"Unnamed: 0\")\n",
    "spark_df.write.saveAsTable(\"wikipedia\")\n",
    "```\n",
    "\n",
    "**N.B.** Durante il loading del dataset, ci appoggiamo ad un dataframe Pandas. Questa non è una procedura comune e del tutto corretta.\n",
    "In questo caso ci permette di leggere correttamente (superando con poco sforzo il limite dei separatori) i dati con cui definire un DataFrame Spark e una Table `Wikipedia`.\n",
    "\n",
    "## Risultati Attesi\n",
    "\n",
    "### 1. Ottimizzazione dell'Organizzazione dei Contenuti\n",
    "\n",
    "L'analisi esplorativa fornirà a Wikimedia una visione chiara e dettagliata della distribuzione e delle caratteristiche dei propri contenuti.\n",
    "Sarà possibile identificare quali categorie necessitano di maggiore attenzione o dove sono presenti opportunità di espansione.\n",
    "\n",
    "### 2. Classificazione Automatica\n",
    "\n",
    "Il sistema di classificazione sviluppato permetterà a Wikimedia di automatizzare il processo di categorizzazione dei nuovi articoli, migliorando l'efficienza operativa e garantendo una migliore navigabilità per gli utenti.\n",
    "\n",
    "### 3. Nuovi Insights Strategici\n",
    "\n",
    "Grazie agli strumenti dell'analisi esplorativa e della classificazione permetteranno a Wikimedia di ottimizzare l'allocazione delle risorse editoriali, con la possibilità di orientare le proprie campagne informative in modo più mirato.\n",
    "\n",
    "## Conclusioni\n",
    "\n",
    "Il progetto offre a **Wikimedia** un potente strumento di **analisi dei dati** e **classificazione automatica** per migliorare la gestione dei propri contenuti.\n",
    "Attraverso l'utilizzo di tecniche avanzate di **data science** e **machine learning**, Wikimedia sarà in grado di ottimizzare la propria infrastruttura informativa e offrire un servizio di qualità superiore agli utenti di tutto il mondo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ebcc9d9f-4d9d-473f-9841-ecedfa2a36b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2675823b-f5f8-4288-95a4-fc83286f0670",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\r\n",
    "\r\n",
    "# Premessa\r\n",
    "\r\n",
    "A causa del recente aggiornamento delle politiche gratuite di Databricks ho riscontrato alcune difficoltà nel completare il compito in cloud, perché:\r\n",
    "\r\n",
    "* il download del dataset tramite `wget` era limitato a **500 MB**;\r\n",
    "* nella versione gratuita di Databricks le librerie **spark.ml** risultano bloccate.\r\n",
    "\r\n",
    "Per aggirare questi vincoli ho configurato e ottimizzato Apache Zeppelin in locale, svolgendo l’esercizio in quell’ambiente (pur con le relative limitazioni).\r\n",
    "\r\n",
    "Di seguito trovate:\r\n",
    "\r\n",
    "1. la **repository pubblica** con la mia configurazione di Zeppelin;\r\n",
    "2. la **repository** contenente il compito in formato **`.zpln`**;\r\n",
    "3. il **notebook Databricks** sul quale ho copiato e versionato gli stessi contenuti, quindi esportato in **`.ipynb`** come richiesto per l’import in questo notebook Colab.\r\n",
    "\r\n",
    "Ecco i tre link alle repository:\r\n",
    "- [Zeppelin Docker Local Tuned](https://github.com/fedevita/zeppelin-docker-local-tuned.git)  \r\n",
    "- [Progetto 8 – Zeppelin (Org. personale dedicata al master)](https://github.com/profession-ai-data-engineering-master/profession_ai_data_engineering_progetto8_zeppelin.git)  \r\n",
    "- [Progetto 8 – Databricks (Org. personale dedicata al master)](https://github.com/profession-ai-data-engineering-master/profession_ai_data_engineering_progetto8_databricks.git)\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41f45b3c-bb46-4e20-80b8-23f9c4bea129",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25ad3285-2a73-43fd-85eb-d1f0e8ad6525",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%python\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from pyspark.sql.functions import (\n",
    "    avg, \n",
    "    max, \n",
    "    min, \n",
    "    length, \n",
    "    count, \n",
    "    desc, \n",
    "    regexp_replace, \n",
    "    col, \n",
    "    lower,\n",
    "    explode,\n",
    "    asc,\n",
    "    desc,\n",
    "    row_number,\n",
    "    struct,\n",
    "    map_from_entries,\n",
    "    collect_list,\n",
    "    concat_ws\n",
    ")\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.sql import Window\n",
    "from pyspark.ml.feature import (\n",
    "    StringIndexer,\n",
    "    Tokenizer,\n",
    "    StopWordsRemover,\n",
    "    CountVectorizer,\n",
    "    HashingTF,\n",
    "    IDF,\n",
    "    StandardScaler,\n",
    "    PCA\n",
    ")\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8be271f0-a0ab-4227-9c74-be3c36bcccb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **O – Obtain (Ottenere i dati)**\n",
    "### Obiettivo:\n",
    "Recuperare e caricare i dati in un ambiente adatto per l'analisi e la modellazione.\n",
    "### Task:\n",
    "#### 1. Scaricare il dataset da `http://proai-dataset.s3.eu-west-3.amazonaws.com/wikipedia.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3694abd3-6416-49ee-89f8-ef02409dc61c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%python\n",
    "!wget --progress=dot:mega https://proai-datasets.s3.eu-west-3.amazonaws.com/wikipedia.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "170f6d7c-4c58-40c2-8e2b-7dfe1ac0c58b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%python\n",
    "wikipedia_raw = (\n",
    "    spark.read.option(\"header\", True)\n",
    "              .option(\"multiLine\", True)\n",
    "              .option(\"quote\", '\"')\n",
    "              .option(\"escape\", '\"')\n",
    "              .csv(\"/databricks/driver/wikipedia.csv\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98fe4fde-e52c-49c2-a7dd-26639a6f3080",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **S – Scrub (Pulizia e preparazione dei dati)**\n",
    "### Obiettivo:\n",
    "Pulire i dati ed effettuare operazioni preliminari per renderli pronti per l’analisi e il modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd318863-9000-47a1-ab36-9550bf0ca98d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# 1. Rimuovere righe duplicate o inconsistenti (es. articoli vuoti)\n",
    "# 2. Gestire eventuali valori nulli (in title, summary, documents, categoria)\n",
    "# 3. Rimuovere o normalizzare caratteri speciali e markup da documents\n",
    "\n",
    "CLEAN_HTML = \"<[^>]+>\"\n",
    "CLEAN_SPECIAL_CHARS = \"[^a-zA-Z0-9\\\\s]\"\n",
    "\n",
    "wikipedia_clean = (\n",
    "    wikipedia_raw\n",
    "    .drop(\"_c0\")\n",
    "    .dropDuplicates()\n",
    "    .dropna(subset=[\"title\", \"summary\", \"documents\", \"categoria\"])\n",
    "    .withColumn(\n",
    "        \"documents\",\n",
    "        lower(regexp_replace(\n",
    "            regexp_replace(\n",
    "                col(\"documents\"),\n",
    "                CLEAN_HTML,\n",
    "                \"\"\n",
    "            ),\n",
    "            CLEAN_SPECIAL_CHARS,\n",
    "            \"\"\n",
    "        ))\n",
    "    )\n",
    ")\n",
    "wikipedia_clean.persist(StorageLevel.DISK_ONLY)\n",
    "wikipedia_clean.count()\n",
    "wikipedia_clean.createOrReplaceTempView(\"wikipedia_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49528ec6-46e5-4180-97f0-4bc15d1f97cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from wikipedia_clean limit 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0cf1a52d-fcd0-4cc0-b921-bcec139651db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **E – Explore (Analisi esplorativa dei dati)**\n",
    "\n",
    "### Obiettivo:\n",
    "\n",
    "Capire la struttura, la distribuzione e le peculiarità dei dati per categoria.\n",
    "\n",
    "### Task:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7135e2ed-6ef1-4598-806a-298ad6334868",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 1. Calcolare il **conteggio articoli per categoria**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a936f2a-85f6-4eb0-8b97-751dd8d849e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%python\n",
    "_ = (wikipedia_clean\n",
    ".groupBy(\"categoria\")\n",
    ".agg(\n",
    "    count(\"*\").alias('documents_cnt')\n",
    ")\n",
    ".sort(desc(\"documents_cnt\"))\n",
    ".createOrReplaceTempView(\"wikipedia_e1\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8642fbd-1f69-432f-9b02-ab5975cfda97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM wikipedia_e1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee7e30b2-1c3e-4906-af3d-cc0009ac845e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 2. Calcolare la **lunghezza media, minima e massima** per articolo per categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c3efdd2-c327-4142-bed3-aa923650c5c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%python\n",
    "_ = (wikipedia_clean\n",
    ".select(\"categoria\",length(\"documents\").alias('documents_len'))\n",
    ".groupBy(\"categoria\")\n",
    ".agg(\n",
    "    max(\"documents_len\").alias(\"max_documents_len\"),\n",
    "    min(\"documents_len\").alias(\"min_documents_len\"),\n",
    "    avg(\"documents_len\").alias(\"avg_documents_len\")\n",
    ")\n",
    ".sort(desc(\"avg_documents_len\"))\n",
    ".createOrReplaceTempView(\"wikipedia_e2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1c6692b-04bb-4b87-9cad-8f2ceba0af1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM wikipedia_e2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e50d0e1f-0077-4ab1-b1f7-1eeb630f59bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 3. Creare **nuvole di parole** per ogni categoria (basate su `documents`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "811b1ac1-afbe-4bb4-b6a8-f5c93e535a58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Creo il dataframe da usare nei grafici wordclouds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d21b056-5329-49b8-849d-628220424865",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# **stabilisco le variabili per effettuare le trasformazioni necessarie al fine di creare grafici di tipo word cloud**\n",
    "LANG   = \"english\"\n",
    "TOP_K  = 50\n",
    "MIN_DF = 2\n",
    "BASE_SW     = StopWordsRemover.loadDefaultStopWords(LANG)\n",
    "NUM_WORDS   = [\"zero\",\"one\",\"two\",\"three\",\"four\",\"five\",\"six\",\"seven\",\"eight\",\"nine\",\n",
    "               \"ten\",\"eleven\",\"twelve\",\"thirteen\",\"fourteen\",\"fifteen\",\"sixteen\",\n",
    "               \"seventeen\",\"eighteen\",\"nineteen\",\"twenty\"]\n",
    "HIGH_DF_SW  = [\"new\",\"also\",\"first\",\"second\",\"one\",\"two\",\"three\",\"later\"]\n",
    "CUSTOM_SW   = [\"’s\",\"“\",\"”\",\"—\",\"http\",\"https\",\"\"]\n",
    "stopwords   = BASE_SW + NUM_WORDS + HIGH_DF_SW + CUSTOM_SW\n",
    "\n",
    "# **Divido in Tokens la colonna documents**\n",
    "tokenizer = Tokenizer(inputCol=\"documents\", outputCol=\"document_tokens\")\n",
    "df_tokens = tokenizer.transform(wikipedia_clean)\n",
    "\n",
    "# **Rimuovo le Stop Words**\n",
    "remover = StopWordsRemover(\n",
    "    inputCol=\"document_tokens\",\n",
    "    outputCol=\"clean_tokens\",\n",
    "    stopWords=stopwords,\n",
    "    caseSensitive=False\n",
    ")\n",
    "\n",
    "df_no_sw = remover.transform(df_tokens)\n",
    "df_clean = df_no_sw.select(\"categoria\", \"clean_tokens\").repartition(\"categoria\")\n",
    "\n",
    "# **Conteggio token per categoria**\n",
    "df_counts = (\n",
    "    df_clean\n",
    "    .select(\"categoria\", explode(\"clean_tokens\").alias(\"token\"))\n",
    "    .groupBy(\"categoria\", \"token\")\n",
    "    .count()\n",
    "    .where(col(\"count\") >= MIN_DF)\n",
    ")\n",
    "\n",
    "# **Effettuo il ranking dei token tramite windows function**\n",
    "# Effettuo il ranking e filtro per `TOP_K`, successivamente raggruppo per categoria e uso `map_from_entries` per creare la colonna `freqs` che sarà un dizionario contenente come chiave la parola e come valore il \n",
    "# conteggio di quante volte la parola compare in quella categoria.\n",
    "w = Window.partitionBy(\"categoria\").orderBy(desc(\"count\"), asc(\"token\"))\n",
    "\n",
    "df_wordcloud = (\n",
    "    df_counts\n",
    "    .withColumn(\"rank\", row_number().over(w))\n",
    "    .where(col(\"rank\") <= TOP_K)\n",
    "    .groupBy(\"categoria\")\n",
    "    .agg(\n",
    "        map_from_entries(\n",
    "            collect_list(struct(\"token\", \"count\"))\n",
    "        ).alias(\"freqs\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# **Mostro e salvo il risultato finale**\n",
    "df_wordcloud.createOrReplaceTempView(\"df_wordcloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6690a84d-d6af-4897-8c22-cb3315b5d375",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from df_wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1be6b49-3c62-46db-bc19-fc75ffd1b316",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Creo i grafici wordcloud**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a98f47c-c14a-41f9-931b-e666b20fdf01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# **Converto Dataframe da Spark a Pandas**\n",
    "# Per agevolarmi nella creazione dei grafici converto il Dataframe da Spark a Pandas.\n",
    "df_wordcloud_pandas = df_wordcloud.sort(\"categoria\").toPandas()\n",
    "\n",
    "# **Calcolo le dimensioni ottimali della griglia in base al numero di categorie**\n",
    "n_cat  = len(df_wordcloud_pandas)\n",
    "n_cols = 5\n",
    "n_rows = math.ceil(n_cat / n_cols)\n",
    "\n",
    "# **Creazione grafici**\n",
    "# Creo la figura e gli `n_rows * n_cols` subplot, impostando dinamicamente la grandezza della figura in pollici \n",
    "# (ho fatto vari tentativi).\n",
    "fig, axes = plt.subplots(\n",
    "    n_rows, n_cols,\n",
    "    figsize=(n_cols * 8, n_rows * 6),\n",
    ")\n",
    "\n",
    "axes = axes.flatten()\n",
    "for idx, (_, row) in enumerate(df_wordcloud_pandas.iterrows()):\n",
    "    ax = axes[idx]\n",
    "    freqs = {token: int(count) for token, count in row[\"freqs\"].items()}\n",
    "    wc = WordCloud(\n",
    "        width=400, height=200,\n",
    "        background_color=\"white\",\n",
    "        colormap=\"tab10\",\n",
    "        prefer_horizontal=1.0\n",
    "    ).generate_from_frequencies(freqs)\n",
    "    ax.imshow(wc, interpolation=\"bilinear\")\n",
    "    ax.set_title(row[\"categoria\"], fontsize=20, pad=10)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4d9773d-5900-4257-ae2f-63c4d57c8b25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **M – Model (Modellazione e machine learning)**\n",
    "\n",
    "### Obiettivo:\n",
    "\n",
    "Addestrare un classificatore per prevedere la categoria degli articoli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e11c8e0a-ac2b-4330-b0c5-2eec0223cb94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# Concatenare le due colonne testuali\n",
    "wikipedia_m0 = wikipedia_clean.withColumn(\"content\", concat_ws(\" \", wikipedia_clean[\"summary\"], wikipedia_clean[\"documents\"])).drop(\"title\",\"summary\",\"documents\").persist(StorageLevel.DISK_ONLY)\n",
    "wikipedia_m0.count()\n",
    "\n",
    "# Preprocessing e pipeline\n",
    "label_indexer = StringIndexer(inputCol=\"categoria\", outputCol=\"label\")\n",
    "tokenizer = Tokenizer(inputCol=\"content\", outputCol=\"tokens\")\n",
    "remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered\")\n",
    "vectorizer = CountVectorizer(inputCol=\"tokens\", outputCol=\"counts\",vocabSize = 10000)\n",
    "scaler1 = StandardScaler(inputCol=\"counts\", outputCol=\"scaled_counts\")\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"scaled_counts\", labelCol=\"label\")\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "label_indexer,\n",
    "tokenizer,\n",
    "remover,\n",
    "vectorizer,\n",
    "scaler1,\n",
    "lr\n",
    "])\n",
    "\n",
    "# Addestramento\n",
    "train_data, test_data = wikipedia_m0.randomSplit([0.8, 0.2], seed=42)\n",
    "model = pipeline.fit(train_data)\n",
    "\n",
    "# Valutazione\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "precision_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "precision = precision_evaluator.evaluate(predictions)\n",
    "print(f\"Weighted Precision: {precision:.4f}\")\n",
    "\n",
    "recall_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "recall = recall_evaluator.evaluate(predictions)\n",
    "print(f\"Weighted Recall: {recall:.4f}\")\n",
    "\n",
    "f1_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = f1_evaluator.evaluate(predictions)\n",
    "print(f\"Weighted F1 Score: {f1:.4f}\")\n",
    "\n",
    "prediction_and_labels = predictions.select(\"prediction\", \"label\").rdd.map(tuple)\n",
    "metrics = MulticlassMetrics(prediction_and_labels)\n",
    "label_indexer_model = label_indexer.fit(wikipedia_m0)\n",
    "labels = label_indexer_model.labels\n",
    "cm = metrics.confusionMatrix().toArray()\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predetto')\n",
    "plt.ylabel('Reale')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "136c736b-d8f0-4850-99e2-a0e8a7a2ed43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# Recupero gli stadi della pipeline\n",
    "vec   = model.stages[3] # CountVectorizerModel\n",
    "lr_md = model.stages[-1] # LogisticRegressionModel\n",
    "\n",
    "vocab  = vec.vocabulary # lista dei token\n",
    "coefs  = lr_md.coefficientMatrix.toArray() # shape = (nClassi, vocabSize)\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "global_imp = np.abs(coefs).mean(axis=0)\n",
    "top20_idx  = global_imp.argsort()[-20:][::-1]\n",
    "\n",
    "top20_dfp = pd.DataFrame({\n",
    "    \"token\": [vocab[i] for i in top20_idx],\n",
    "    \"peso\" : global_imp[top20_idx]\n",
    "})\n",
    "\n",
    "top20_df = spark.createDataFrame(top20_dfp)\n",
    "\n",
    "top20_df.createOrReplaceTempView(\"top20_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d213b60-9bdd-4079-b377-e09612962589",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "autoscroll": "auto"
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from top20_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae3f669d-6053-441c-9c19-16c6969d2273",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\r\n",
    "## Risultati del modello di classificazione\r\n",
    "\r\n",
    "> *Disclaimer*: Il modello attuale è **molto semplice e limitato** perché sto lavorando in ambiente **locale** con **risorse ridotte**.  \r\n",
    "> L'obiettivo è ottenere una baseline funzionante, non ottimizzare al massimo le prestazioni.\r\n",
    "\r\n",
    "- **Accuracy**: 0.8491  \r\n",
    "- **Weighted Precision**: 0.8505  \r\n",
    "- **Weighted Recall**: 0.8491  \r\n",
    "- **Weighted F1 Score**: 0.8497  \r\n",
    "\r\n",
    "### Considerazioni\r\n",
    "- Le metriche sono **coerenti** e indicano un **modello bilanciato**.  \r\n",
    "- La **confusion matrix** conferma che la maggior parte delle classi è ben gestita, con solo lievi confusioni tra classi affini.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e362552-4b32-476d-829b-4ae470a966dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\r\n",
    "## **N – iNterpret (Interpretazione dei risultati)**\r\n",
    "\r\n",
    "### Obiettivo:\r\n",
    "\r\n",
    "Fornire una lettura chiara e strategica dei risultati ottenuti.\r\n",
    "\r\n",
    "### Task:\r\n",
    "\r\n",
    "### 1. Sintesi dei risultati dell’EDA\r\n",
    "\r\n",
    "* **Distribuzione delle categorie**\r\n",
    "\r\n",
    "  * Gli articoli non sono equamente distribuiti.\r\n",
    "  * `medicine` domina con **8.311 articoli**.\r\n",
    "  * `politics`, `culture` e `sports` contano meno della metà di `medicine`.\r\n",
    "  * *Rischio*: i modelli potrebbero favorire le classi più frequenti.\r\n",
    "\r\n",
    "* **Lunghezza dei testi per categoria**\r\n",
    "\r\n",
    "  * `politics` contiene in media i testi più lunghi, mentre `pets` ha lunghezze medie basse.\r\n",
    "  * Tutte le categorie presentano lunghezza minima e massima molto distanti, il che è un forte segnale di varianza interna.\r\n",
    "  * *Effetto sui modelli*: sequenze molto eterogenee rendono l'apprendimento instabile e penalizzano le categorie con meno contenuto.\r\n",
    "\r\n",
    "* **Word‑Cloud per categoria**\r\n",
    "\r\n",
    "  * Buona coerenza lessicale in `medicine`, `research`, `energy`, `transport`, `politics`.\r\n",
    "  * Rumore/ambiguità:\r\n",
    "\r\n",
    "    * `trade` contiene termini geografici‑storici.\r\n",
    "    * `culture` mostra parole legate a rituali funebri (*cemetery*).\r\n",
    "    * `engineering` è contaminata da contenuti geografico‑culturali.\r\n",
    "  * Alcune categorie ignorano concetti chiave: in `technology` prevalgono *games* a scapito di *AI*, *IoT*, *cloud*.\r\n",
    "\r\n",
    "### 2. Analisi dei 20 token più importanti in relazione all'EDA\r\n",
    " \r\n",
    "* **Bias sanitario**: 4 token su 20 (hospital, medical, medicine, research) appartengono a `medicine`, accentuando lo sbilanciamento già evidenziato nella distribuzione delle categorie.\r\n",
    "\r\n",
    "* **Contaminazione geografica**: *dresden* e *saxony* occupano posizioni alte; documenti storici‑locali penetrano categorie economiche (`trade`) o ingegneristiche.\r\n",
    "\r\n",
    "* **Ambiguità lessicale**: token come *polo*, *bridge* e *station* mostrano la sovrapposizione di significati (sport vs. moda, infrastruttura vs. monumento).\r\n",
    "\r\n",
    "### 3. Raccomandazioni per l'organizzazione dei contenuti su Wikipedia\r\n",
    "\r\n",
    "* **Disambiguazione geografica**: Introdurre un tag dove collocare voci come `dresden`, `saxony`, `bridge` (monumenti storici) e `cemetery`. \r\n",
    "\r\n",
    "* **Uniformità nella lunghezza dei contenuti**: Introdurre linee guida editoriali per garantire una lunghezza coerente tra articoli della stessa categoria.\r\n",
    "\r\n",
    "* **Revisione semantica delle categorie**: Eseguire un audit semantico per ricollocare articoli fuori tema: ad esempio, spostare contenuti su games fuori da technology se non trattano \r\n",
    "innovazione tecnologica, o separare rituali funebri dalla categoria culture. Questo ridurrebbe l'ambiguità lessicale e aumenterebbe la coerenza semantica delle categorie."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "scala",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "profession_ai_data_engineering_progetto8_databricks",
   "widgets": {}
  },
  "kernelspec": {
   "language": "scala",
   "name": "spark2-scala"
  },
  "language_info": {
   "name": "scala"
  },
  "name": "profession_ai_data_engineering_progetto8_local"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}